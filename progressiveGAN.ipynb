{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42aa7f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "import keras\n",
    "import keras.layers as lay\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747e7576",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0800d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "opt = [keras.optimizers.Adam(1e-4,.5),keras.optimizers.Adam(1e-4,.5)]\n",
    "bce = keras.losses.BinaryCrossentropy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9aceff",
   "metadata": {},
   "source": [
    "# Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0edaa4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Fade_in(keras.Layer):\n",
    "    def __init__(self, alpha=0.0, activity_regularizer=None, trainable=True, dtype=None, autocast=True, name=None, **kwargs):\n",
    "        super().__init__(activity_regularizer=activity_regularizer, trainable=trainable, dtype=dtype, autocast=autocast, name=name, **kwargs)\n",
    "        self.alpha = tf.Variable(alpha,trainable=False)\n",
    "\n",
    "    def call(self,inputs):\n",
    "        antigo, novo = inputs\n",
    "        return self.alpha*novo + (1-self.alpha)*antigo\n",
    "        \n",
    "\n",
    "def g_block(x, filters):\n",
    "    x = lay.UpSampling2D((2,2))(x)\n",
    "    x = lay.Conv2D(filters,(3,3),(1,1),'same')(x)\n",
    "    x = lay.LeakyReLU(.2)(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def build_generator_4x4(latent_dim=128):\n",
    "    inputs = lay.Input((latent_dim,))\n",
    "    x = inputs\n",
    "    x = lay.Dense(4*4*512,activation='leaky_relu')(x)\n",
    "    x = lay.Reshape((4,4,512),name='lastfeat_4x4')(x)\n",
    "    img_output = lay.Conv2D(3,(1,1),(1,1),'same',activation='tanh',name='toRGB_4x4')(x)\n",
    "    return keras.Model(inputs,img_output,name='Generator_4x4')\n",
    "\n",
    "def build_generator_8x8(g_4x4):\n",
    "    latent_input = g_4x4.input\n",
    "    g_4x4.trainable = False\n",
    "    last_featuremap = g_4x4.get_layer('lastfeat_4x4').output\n",
    "    old_path = lay.UpSampling2D((2,2))(g_4x4.output)\n",
    "    x = g_block(last_featuremap,512)\n",
    "    new_path = lay.Conv2D(3,(1,1),(1,1),'same',activation='tanh',name='toRGB_8x8')(x)\n",
    "    output_fade_in = Fade_in(name='fade_8')([old_path,new_path])\n",
    "    return keras.Model(latent_input,output_fade_in,name='Generator_8x8')\n",
    "\n",
    "def build_generator_16x16(g_8x8):\n",
    "    latent_input = g_8x8.input\n",
    "    g_8x8.trainable = False\n",
    "    last_featuremap = g_8x8.layers[-4].output\n",
    "    old_path = lay.UpSampling2D((2,2))(g_8x8.output)\n",
    "    x = g_block(last_featuremap,512)\n",
    "    new_path = lay.Conv2D(3,(1,1),(1,1),'same',activation='tanh',name='toRGB_16x16')(x)\n",
    "    output_fade_in = Fade_in(name='fade_16')([old_path,new_path])\n",
    "    return keras.Model(latent_input,output_fade_in,name='Generator_16x16')\n",
    "\n",
    "def build_generator_32x32(g_16x16):\n",
    "    latent_input = g_16x16.input\n",
    "    g_16x16.trainable = False\n",
    "    last_featuremap = g_16x16.layers[-4].output\n",
    "    old_path = lay.UpSampling2D((2,2))(g_16x16.output)\n",
    "    x = g_block(last_featuremap,512)\n",
    "    new_path = lay.Conv2D(3,(1,1),(1,1),'same',activation='tanh',name='toRGB_32x32')(x)\n",
    "    output_fade_in = Fade_in(name='fade_32')([old_path,new_path])\n",
    "    return keras.Model(latent_input,output_fade_in,name='Generator_32x32')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252160da",
   "metadata": {},
   "source": [
    "# Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7823989",
   "metadata": {},
   "outputs": [],
   "source": [
    "def d_block(x,filters,name):\n",
    "    x = lay.Conv2D(filters,(3,3),(1,1),'same',activation='leaky_relu',name=f'conv{name}_1')(x)\n",
    "    x = lay.Conv2D(filters,(3,3),(1,1),'same',activation='leaky_relu',name=f'conv{name}_2')(x)\n",
    "    return x\n",
    "\n",
    "def build_discriminator_4x4(filters=128):\n",
    "    inputs = lay.Input((4,4,3))\n",
    "    x = inputs\n",
    "    x = lay.Conv2D(128,(3,3),(1,1),'same',activation='leaky_relu',name='fromRGB_4x4')(x)\n",
    "    x = lay.Conv2D(filters,(3,3),(1,1),'same',activation='leaky_relu',name='conv4_1')(x)\n",
    "    x = lay.Conv2D(filters,(3,3),(1,1),'same',activation='leaky_relu',name='conv4_2')(x)\n",
    "    x = lay.Flatten(name='flatten')(x)\n",
    "    x = lay.Dense(1,activation='sigmoid',name='brain')(x)\n",
    "    return keras.Model(inputs,x)\n",
    "\n",
    "def build_discriminator_8x8(d_4x4, filters=128):\n",
    "    inputs = lay.Input((8,8,3))\n",
    "\n",
    "    # Caminho Novo\n",
    "    x = inputs\n",
    "    x = lay.Conv2D(128,(3,3),(1,1),'same',activation='leaky_relu',name='fromRGB_8x8')(x)\n",
    "    x = d_block(x,128,8)\n",
    "    new_path = lay.AvgPool2D((2,2),name='pool8_1')(x)\n",
    "\n",
    "    # Caminho antigo\n",
    "    x = inputs\n",
    "    x = lay.AvgPool2D((2,2))(x)\n",
    "    old_path = d_4x4.layers[1](x)\n",
    "\n",
    "    # União dos caminhos\n",
    "    output_fade_in = Fade_in(name='fade_8')([old_path,new_path])\n",
    "    x = output_fade_in\n",
    "\n",
    "    # for i in range(2,len(d_4x4.layers)):\n",
    "    #     x = d_4x4.layers[i](x)\n",
    "    for i in range(2,len(d_4x4.layers)):\n",
    "        x = d_4x4.layers[i](x)\n",
    "    \n",
    "    return keras.Model(inputs,x)\n",
    "\n",
    "def build_discriminator_16x16(d_8x8, filters=128):\n",
    "    inputs = lay.Input((16,16,3))\n",
    "\n",
    "    # Caminho Novo\n",
    "    x = inputs\n",
    "    x = lay.Conv2D(128,(3,3),(1,1),'same',activation='leaky_relu',name='fromRGB_16x16')(x)\n",
    "    x = d_block(x,128,16)\n",
    "    new_path = lay.AvgPool2D((2,2),name='pool16_1')(x) # shape (None, 8, 8, 128)\n",
    "\n",
    "    # Caminho antigo\n",
    "    x = inputs\n",
    "    x = lay.AvgPool2D((2,2))(x) # shape (None, 8, 8, 3)\n",
    "    old_path = d_8x8.layers[1](x)\n",
    "\n",
    "    # União dos caminhos\n",
    "    output_fade_in = Fade_in(name='fade_16')([old_path,new_path])\n",
    "    x = output_fade_in\n",
    "\n",
    "    path = ['conv8_1','conv8_2','pool8_1','conv4_1','conv4_2','flatten','brain']\n",
    "    for name in path:\n",
    "        x = d_8x8.get_layer(name)(x)\n",
    "    \n",
    "    return keras.Model(inputs,x)\n",
    "\n",
    "def build_discriminator_32x32(d_16x16, filters=128):\n",
    "    inputs = lay.Input((32,32,3))\n",
    "\n",
    "    # Caminho Novo\n",
    "    x = inputs\n",
    "    x = lay.Conv2D(128,(3,3),(1,1),'same',activation='leaky_relu',name='fromRGB_32x32')(x)\n",
    "    x = d_block(x,128,32)\n",
    "    new_path = lay.AvgPool2D((2,2),name='pool32_1')(x) # shape (None, 8, 8, 128)\n",
    "\n",
    "    # Caminho antigo\n",
    "    x = inputs\n",
    "    x = lay.AvgPool2D((2,2))(x) # shape (None, 8, 8, 3)\n",
    "    old_path = d_16x16.layers[1](x)\n",
    "\n",
    "    # União dos caminhos\n",
    "    output_fade_in = Fade_in(name='fade_32')([old_path,new_path])\n",
    "    x = output_fade_in\n",
    "\n",
    "    path = ['conv16_1','conv16_2','pool16_1','conv8_1','conv8_2','pool8_1','conv4_1','conv4_2','flatten','brain']\n",
    "    for name in path:\n",
    "        x = d_16x16.get_layer(name)(x)\n",
    "    \n",
    "    return keras.Model(inputs,x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc27a6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_4x4 = build_generator_4x4()\n",
    "# g_8x8 = build_generator_8x8(g_4x4)\n",
    "# g_16x16 = build_generator_16x16(g_8x8)\n",
    "# g_32x32 = build_generator_32x32(g_16x16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08c53c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_4x4 = build_discriminator_4x4(filters=512)\n",
    "# d_8x8 = build_discriminator_8x8(d_4x4,128)\n",
    "# d_16x16 = build_discriminator_16x16(d_8x8,128)\n",
    "# d_32x32 = build_discriminator_32x32(d_16x16,128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b350cd5a",
   "metadata": {},
   "source": [
    "# Função de passo de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3291e8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(gan,batch,opt,bce):\n",
    "    g_loss = 0.\n",
    "    d_loss = 0.\n",
    "    batch_size = tf.shape(batch)[0]\n",
    "    noise = tf.random.normal((2*batch_size,128),0,1)\n",
    "    with tf.GradientTape() as tape:\n",
    "        fake_imgs = gan[0](noise, training=True)\n",
    "        fake_logits = gan[1](fake_imgs, training=True)\n",
    "        g_loss = bce(tf.ones_like(fake_logits),fake_logits)\n",
    "    grads = tape.gradient(g_loss,gan[0].trainable_variables)\n",
    "    opt[0].apply_gradients(zip(grads,gan[0].trainable_variables))\n",
    "\n",
    "    noise = tf.random.normal((batch_size,128),0,1)\n",
    "    with tf.GradientTape() as tape:\n",
    "        fake_imgs = gan[0](noise,training=True)\n",
    "        fake_logits = gan[1](fake_imgs,training=True)\n",
    "        true_logits = gan[1](batch,training=True)\n",
    "        d_loss += bce(tf.zeros_like(fake_logits),fake_logits) + bce(tf.ones_like(true_logits),true_logits)\n",
    "        d_loss /= 2\n",
    "    grads = tape.gradient(d_loss,gan[1].trainable_variables)\n",
    "    opt[1].apply_gradients(zip(grads,gan[1].trainable_variables))\n",
    "    return g_loss, d_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a44f76",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e55f9c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x,y),(_,_) = keras.datasets.cifar10.load_data()\n",
    "x = x[y[:,0]==1]\n",
    "x = (tf.cast(x,tf.float32)-127.5)/127.5\n",
    "x = tf.image.resize(x,(4,4))\n",
    "train_4x4 = tf.data.Dataset.from_tensor_slices((tf.image.resize(x,(4,4)))).cache().shuffle(1024).batch(batch_size,drop_remainder=True).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb4fa917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: 0.6944639682769775; D: 0.6940869092941284\n",
      "G: 0.684400200843811; D: 0.6743226647377014\n",
      "G: 0.6763319969177246; D: 0.6546305418014526\n",
      "G: 0.665186882019043; D: 0.6353511810302734\n",
      "G: 0.6562385559082031; D: 0.6183775663375854\n",
      "G: 0.6433091759681702; D: 0.609485924243927\n",
      "G: 0.6262623071670532; D: 0.5878362655639648\n",
      "G: 0.6077922582626343; D: 0.5826013088226318\n",
      "G: 0.589589536190033; D: 0.5574988722801208\n",
      "G: 0.5861729383468628; D: 0.5718101263046265\n",
      "G: 0.5753055214881897; D: 0.5612285137176514\n",
      "G: 0.5624241828918457; D: 0.5629803538322449\n",
      "G: 0.5575814247131348; D: 0.5561191439628601\n",
      "G: 0.5567529201507568; D: 0.5582883358001709\n",
      "G: 0.5793899893760681; D: 0.5828688144683838\n",
      "G: 0.5862235426902771; D: 0.5363423824310303\n",
      "G: 0.5803622007369995; D: 0.5644469261169434\n",
      "G: 0.5885434150695801; D: 0.5654316544532776\n",
      "G: 0.5907149314880371; D: 0.5457075834274292\n",
      "G: 0.5975813865661621; D: 0.512597382068634\n",
      "G: 0.5779749155044556; D: 0.5453053116798401\n",
      "G: 0.604117751121521; D: 0.5565358996391296\n",
      "G: 0.6061747074127197; D: 0.549037516117096\n",
      "G: 0.6335103511810303; D: 0.5360766649246216\n",
      "G: 0.5785990953445435; D: 0.5542299747467041\n",
      "G: 0.6027102470397949; D: 0.5636252164840698\n",
      "G: 0.633920431137085; D: 0.5525369048118591\n",
      "G: 0.6553307175636292; D: 0.5071251392364502\n",
      "G: 0.6748917102813721; D: 0.48549884557724\n",
      "G: 0.7230063080787659; D: 0.48412302136421204\n",
      "G: 0.7418773174285889; D: 0.487643837928772\n",
      "G: 0.7642416954040527; D: 0.43776535987854004\n",
      "G: 0.8248072862625122; D: 0.4473996162414551\n",
      "G: 0.8825193643569946; D: 0.426918625831604\n",
      "G: 0.8741123676300049; D: 0.41169899702072144\n",
      "G: 0.8545451164245605; D: 0.446328341960907\n",
      "G: 0.8325669765472412; D: 0.443219393491745\n",
      "G: 0.8852036595344543; D: 0.43968939781188965\n",
      "G: 1.0522218942642212; D: 0.44026678800582886\n",
      "G: 0.7647842168807983; D: 0.4715386629104614\n",
      "G: 0.9484097957611084; D: 0.46731671690940857\n",
      "G: 1.1449216604232788; D: 0.5066092610359192\n",
      "G: 0.6340343356132507; D: 0.5113443732261658\n",
      "G: 0.96430903673172; D: 0.404992014169693\n",
      "G: 1.2256996631622314; D: 0.509706974029541\n",
      "G: 0.9810558557510376; D: 0.4381066560745239\n",
      "G: 0.8364551067352295; D: 0.48759710788726807\n",
      "G: 1.0226032733917236; D: 0.453243613243103\n",
      "G: 1.1576319932937622; D: 0.41676655411720276\n",
      "G: 1.1845650672912598; D: 0.4642203450202942\n",
      "G: 0.8322762846946716; D: 0.5298891067504883\n",
      "G: 1.3815667629241943; D: 0.6161701083183289\n",
      "G: 0.8187378644943237; D: 0.47706377506256104\n",
      "G: 0.7539291977882385; D: 0.4793303310871124\n",
      "G: 1.0285234451293945; D: 0.4420257806777954\n",
      "G: 1.2219996452331543; D: 0.5820139050483704\n",
      "G: 0.9405784606933594; D: 0.5169200897216797\n",
      "G: 0.8398138284683228; D: 0.5709046125411987\n",
      "G: 1.1464543342590332; D: 0.5416303873062134\n",
      "G: 0.9107590913772583; D: 0.5861731171607971\n",
      "G: 0.8204647302627563; D: 0.5290343165397644\n",
      "G: 0.9520291090011597; D: 0.4879569411277771\n",
      "G: 0.9155352115631104; D: 0.5152161717414856\n",
      "G: 1.105149745941162; D: 0.48334619402885437\n",
      "G: 0.8886337280273438; D: 0.45031148195266724\n",
      "G: 0.8479398488998413; D: 0.5272802114486694\n",
      "G: 1.0820612907409668; D: 0.515379011631012\n",
      "G: 1.1591665744781494; D: 0.538848876953125\n",
      "G: 1.3704559803009033; D: 0.5682732462882996\n",
      "G: 0.6732762455940247; D: 0.5873004794120789\n",
      "G: 0.9438104629516602; D: 0.4818832576274872\n",
      "G: 1.106044054031372; D: 0.6103450655937195\n",
      "G: 0.9270215630531311; D: 0.44845205545425415\n",
      "G: 0.9129734039306641; D: 0.5282659530639648\n",
      "G: 0.9401752948760986; D: 0.6066478490829468\n",
      "G: 1.1835107803344727; D: 0.6841758489608765\n",
      "G: 0.9204676151275635; D: 0.531740665435791\n",
      "G: 0.7555457949638367; D: 0.6064984798431396\n",
      "G: 1.2865748405456543; D: 0.658076286315918\n",
      "G: 0.9814123511314392; D: 0.5476447343826294\n",
      "G: 0.919251024723053; D: 0.5963553786277771\n",
      "G: 1.0686663389205933; D: 0.45385682582855225\n",
      "G: 1.1436543464660645; D: 0.48370060324668884\n",
      "G: 0.745574951171875; D: 0.567175030708313\n",
      "G: 1.0824806690216064; D: 0.5535018444061279\n",
      "G: 1.013174057006836; D: 0.5360825657844543\n",
      "G: 1.1824769973754883; D: 0.543379008769989\n",
      "G: 0.8723822832107544; D: 0.5143804550170898\n",
      "G: 1.0359550714492798; D: 0.5839220285415649\n",
      "G: 0.9615103006362915; D: 0.6293739676475525\n",
      "G: 1.0078526735305786; D: 0.6102578639984131\n",
      "G: 0.6474379897117615; D: 0.701470136642456\n",
      "G: 1.0747697353363037; D: 0.6014090776443481\n",
      "G: 1.1886969804763794; D: 0.6382409334182739\n",
      "G: 0.6961392164230347; D: 0.6417583227157593\n",
      "G: 0.7924607992172241; D: 0.6055841445922852\n",
      "G: 1.0663986206054688; D: 0.6335669755935669\n",
      "G: 0.8451687693595886; D: 0.6920161247253418\n",
      "G: 0.7002264261245728; D: 0.7413175702095032\n",
      "G: 1.0147500038146973; D: 0.5884286761283875\n",
      "G: 0.8953630924224854; D: 0.5521354675292969\n",
      "G: 0.7201195955276489; D: 0.6652891635894775\n",
      "G: 1.23459792137146; D: 0.7009012699127197\n",
      "G: 1.113229513168335; D: 0.7008676528930664\n",
      "G: 0.7966268062591553; D: 0.6301952600479126\n",
      "G: 0.8361389636993408; D: 0.686152994632721\n",
      "G: 0.9638593196868896; D: 0.647187352180481\n",
      "G: 1.0046827793121338; D: 0.6305908560752869\n",
      "G: 0.8569039106369019; D: 0.7277876138687134\n",
      "G: 0.6275941729545593; D: 0.6669056415557861\n",
      "G: 0.9176932573318481; D: 0.6921805739402771\n",
      "G: 0.9660171866416931; D: 0.6765486001968384\n",
      "G: 0.8945903778076172; D: 0.719322681427002\n",
      "G: 0.708586573600769; D: 0.5980211496353149\n",
      "G: 0.7815789580345154; D: 0.7101766467094421\n",
      "G: 1.0405287742614746; D: 0.7164475321769714\n",
      "G: 0.8792535662651062; D: 0.6199866533279419\n",
      "G: 0.7337949275970459; D: 0.7048759460449219\n",
      "G: 0.805054783821106; D: 0.7282059192657471\n",
      "G: 0.9043377637863159; D: 0.6790436506271362\n",
      "G: 0.9621291160583496; D: 0.6898301243782043\n",
      "G: 0.7378344535827637; D: 0.6517874002456665\n",
      "G: 0.8776437640190125; D: 0.6361016035079956\n",
      "G: 0.8555358052253723; D: 0.6686026453971863\n",
      "G: 0.7726843357086182; D: 0.7169960141181946\n",
      "G: 0.9400262832641602; D: 0.7509151697158813\n",
      "G: 0.7974098324775696; D: 0.7311286926269531\n",
      "G: 0.790695309638977; D: 0.7212589383125305\n",
      "G: 0.7392855286598206; D: 0.6893462538719177\n",
      "G: 0.8157327771186829; D: 0.7019387483596802\n",
      "G: 0.9513360261917114; D: 0.6626632809638977\n",
      "G: 0.7954609394073486; D: 0.6849467754364014\n",
      "G: 0.805479884147644; D: 0.6724497079849243\n",
      "G: 0.8402122259140015; D: 0.6750393509864807\n",
      "G: 0.8130136132240295; D: 0.6986579895019531\n",
      "G: 0.7475955486297607; D: 0.7413572072982788\n",
      "G: 0.771231472492218; D: 0.7013651728630066\n",
      "G: 0.7810252904891968; D: 0.7008411884307861\n",
      "G: 0.7606183290481567; D: 0.6812528371810913\n",
      "G: 0.8385555744171143; D: 0.6802141070365906\n",
      "G: 0.7792375087738037; D: 0.71197509765625\n",
      "G: 0.88858962059021; D: 0.7357909679412842\n",
      "G: 0.8535728454589844; D: 0.7068147659301758\n",
      "G: 0.744425356388092; D: 0.7019349336624146\n",
      "G: 0.797321081161499; D: 0.736365556716919\n",
      "G: 0.7522149682044983; D: 0.6833248734474182\n",
      "G: 0.7314903736114502; D: 0.7457389831542969\n",
      "G: 0.822256326675415; D: 0.6862109899520874\n",
      "G: 0.8816609978675842; D: 0.705481231212616\n",
      "G: 0.8620629906654358; D: 0.7719149589538574\n",
      "G: 0.8512137532234192; D: 0.7306471467018127\n",
      "G: 0.7303329706192017; D: 0.7008918523788452\n",
      "G: 0.801576554775238; D: 0.6849401593208313\n",
      "G: 0.8231344223022461; D: 0.7205866575241089\n",
      "G: 0.835111677646637; D: 0.6782358884811401\n",
      "G: 0.821322500705719; D: 0.6872378587722778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-29 10:31:21.903267: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "for batch in train_4x4:\n",
    "    g_loss, d_loss = train_step([g_4x4,d_4x4],batch,opt,bce)\n",
    "    print(f'G: {g_loss}; D: {d_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5178c982",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
